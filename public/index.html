<!DOCTYPE html>
<html>
  <head>
    <script lang="text/javascript" src="/socket.io/socket.io.js"></script>
    <script src="/simple-peer/simplepeer.min.js"></script>
    <style>
      body {
        background-color: rgb(255, 255, 255);
        font-family: Arial, sans-serif;
        color: white;
        margin: 0;
        height: 100vh;
        overflow: hidden;
      }

      .main-container {
        display: flex;
        height: 100vh;
      }

      /* Left sidebar for chat */
      .chat-sidebar {
        width: 300px;
        background: rgba(56, 56, 56, 0.8);
        padding: 15px;
        display: flex;
        flex-direction: column;
        gap: 10px;
        border-right: 1px solid rgba(255, 255, 255, 0.1);
      }

      .user-list {
        background: rgba(0, 0, 0, 0.3);
        padding: 10px;
        border-radius: 8px;
        max-height: 150px;
        overflow-y: auto;
      }

      .chat-messages {
        flex-grow: 1;
        background: rgba(0, 0, 0, 0.3);
        border-radius: 8px;
        padding: 10px;
        overflow-y: auto;
        margin: 10px 0;
      }

      .chat-input {
        display: flex;
        gap: 10px;
        padding: 10px;
      }

      /* Main content area */
      .content-area {
        flex-grow: 1;
        display: flex;
        flex-direction: column;
        position: relative;
      }

      /* Main video container */
      .video-container {
        flex-grow: 1;
        display: flex;
        flex-wrap: wrap;
        gap: 20px;
        justify-content: center;
        align-items: center;
        padding: 20px;
        overflow-y: auto;
      }

      .remote-video {
        width: 45%;
        min-width: 300px;
        max-height: 400px;
        border-radius: 10px;
        background: rgba(56, 56, 56, 0.8);
      }

      /* Local video (bottom right) */
      #localVideo {
        position: fixed;
        bottom: 100px;
        right: 20px;
        width: 250px;
        height: 180px;
        border-radius: 10px;
        z-index: 100;
        background: rgba(0, 0, 0, 0.5);
      }

      /* Controls bar */
      .controls-bar {
        padding: 15px;
        background: rgba(56, 56, 56, 0.8);
        display: flex;
        justify-content: center;
        gap: 20px;
        border-top: 1px solid rgba(255, 255, 255, 0.1);
      }

      /* Transcription box */
      #transcription-box {
        position: fixed;
        bottom: 80px;
        left: 320px; /* Adjusted to account for sidebar */
        right: 20px;
        background: rgba(0, 0, 0, 0.7);
        border-radius: 8px;
        padding: 15px;
        z-index: 90;
      }

      /* Enhanced button styles */
      .settings {
        background: rgba(255, 255, 255, 0.2);
        border: none;
        color: white;
        padding: 10px 20px;
        border-radius: 20px;
        cursor: pointer;
        transition: all 0.3s ease;
      }

      .settings:hover {
        background: rgba(255, 255, 255, 0.3);
      }

      .settings:disabled {
        opacity: 0.5;
        cursor: not-allowed;
      }

      /* Input styles */
      input[type="text"] {
        background: rgba(255, 255, 255, 0.1);
        border: 1px solid rgba(255, 255, 255, 0.2);
        border-radius: 20px;
        padding: 8px 15px;
        color: white;
        flex-grow: 1;
      }

      input[type="text"]::placeholder {
        color: rgba(255, 255, 255, 0.5);
      }

      select.settings {
        background: rgba(255, 255, 255, 0.2);
        color: white;
        padding: 8px 15px;
      }

      /* Scrollbar styling */
      ::-webkit-scrollbar {
        width: 8px;
      }

      ::-webkit-scrollbar-track {
        background: rgba(0, 0, 0, 0.2);
        border-radius: 4px;
      }

      ::-webkit-scrollbar-thumb {
        background: rgba(255, 255, 255, 0.2);
        border-radius: 4px;
      }
    </style>
  </head>
  <body>
    <div class="main-container">
      <!-- Left Chat Sidebar -->
      <div class="chat-sidebar">
        <div class="user-list" id="user-list">
          <!-- User checkboxes will be populated here -->
        </div>
        <div class="chat-messages" id="chat-messages">
          <!-- Chat messages will appear here -->
        </div>
        <div class="chat-input">
          <input type="text" id="message-input" placeholder="Type your message..." />
          <button class="settings" onclick="sendMessage()">Send</button>
        </div>
      </div>

      <!-- Main Content Area -->
      <div class="content-area">
        <!-- Main Video Container -->
        <div class="video-container" id="videos">
          <!-- Remote video streams will be added here -->
        </div>

        <!-- Controls Bar -->
        <div class="controls-bar">
          <button id="muteButton" class="settings" onclick="toggleMute()">Mute</button>
          <button id="vidButton" class="settings" onclick="toggleVid()">Video</button>
          <select id="language" class="settings">
            <option value="en">English</option>
            <option value="hi">Hindi</option>
          </select>
          <button id="startBtn" class="settings">Start Recording</button>
          <button id="stopBtn" class="settings" disabled>Stop Recording</button>
        </div>
      </div>

      <!-- Local Video -->
      <video id="localVideo" autoplay muted></video>

      <!-- Transcription Box -->
      <div id="transcription-box">
        <div class="transcription-text"></div>
      </div>
    </div>


    <footer>
      <script src="/js/main.js" lang="text/javascript"></script>
      <script>
        // Add this inline script to ensure sendMessage is defined before use
        function sendMessageHandler() {
          // This will call the sendMessage function from main.js
          if (typeof sendMessage === "function") {
            sendMessage();
          } else {
            console.error("sendMessage function is not defined");
          }
        }
      </script>

      <script>
        // AudioWorklet processor code as a string
        const workletCode = `
      class AudioProcessor extends AudioWorkletProcessor {
          constructor() {
              super();
              this.bufferSize = 8192;
              this.buffer = new Float32Array(this.bufferSize);
              this.bufferedSamples = 0;
          }

          process(inputs, outputs, parameters) {
              const input = inputs[0][0];
              if (!input) return true;

              // Add incoming samples to buffer
              for (let i = 0; i < input.length; i++) {
                  this.buffer[this.bufferedSamples] = input[i];
                  this.bufferedSamples++;

                  // When buffer is full, send it to main thread
                  if (this.bufferedSamples >= this.bufferSize) {
                      const int16Data = new Int16Array(this.bufferSize);
                      for (let j = 0; j < this.bufferSize; j++) {
                          int16Data[j] = Math.max(-32768, Math.min(32767, this.buffer[j] * 32768));
                      }
                      this.port.postMessage(int16Data.buffer, [int16Data.buffer]);
                      
                      // Reset buffer
                      this.buffer = new Float32Array(this.bufferSize);
                      this.bufferedSamples = 0;
                  }
              }
              return true;
          }
      }
      registerProcessor('audio-processor', AudioProcessor);
  `;

        let websocket;
        let audioContext;
        let workletNode;
        const outputDiv = document.getElementById("output");
        const startBtn = document.getElementById("startBtn");
        const stopBtn = document.getElementById("stopBtn");
        const languageSelect = document.getElementById("language");

        async function initAudioWorklet() {
          const blob = new Blob([workletCode], {
            type: "application/javascript",
          });
          const workletUrl = URL.createObjectURL(blob);
          await audioContext.audioWorklet.addModule(workletUrl);
          URL.revokeObjectURL(workletUrl);
        }

        startBtn.onclick = async () => {
          try {
            // Connect to WebSocket server
            websocket = new WebSocket("ws://localhost:8765");

            websocket.onopen = () => {
              websocket.send(
                JSON.stringify({
                  language: languageSelect.value,
                })
              );
            };

            // websocket.onmessage = (event) => {
            //   const data = JSON.parse(event.data);
            //   if (data.type === "final") {
            //     // Set the transcribed text to the message input field
            //     const messageInput = document.getElementById("message-input");
            //     messageInput.value = data.text;

            //     // Call the sendMessage function to send the transcribed message
            //     if (typeof sendCaption === "function") {
            //       sendCaption();
            //     } else {
            //       console.error("sendMessage function is not defined");
            //     }
            //   }
            // };

            websocket.onmessage = (event) => {
              const data = JSON.parse(event.data);
              if (data.type === "final") {
                // Only send to peers, don't display locally
                const transcriptionData = {
                  text: data.text,
                  sender: socket.id,
                  type: "transcription",
                };

                // Emit transcription to peers
                socket.emit("transcription", transcriptionData);
              }
            };

            // Get audio stream
            const stream = await navigator.mediaDevices.getUserMedia({
              audio: true,
            });

            // Initialize audio context and worklet
            audioContext = new AudioContext({
              sampleRate: 16000, // Match Vosk's expected sample rate
              latencyHint: "interactive",
            });

            await initAudioWorklet();

            const source = audioContext.createMediaStreamSource(stream);
            workletNode = new AudioWorkletNode(audioContext, "audio-processor");

            workletNode.port.onmessage = (e) => {
              if (websocket.readyState === WebSocket.OPEN) {
                websocket.send(e.data);
              }
            };

            source.connect(workletNode);
            workletNode.connect(audioContext.destination);

            startBtn.disabled = true;
            stopBtn.disabled = false;
          } catch (error) {
            console.error("Error:", error);
            alert("Error starting recording: " + error.message);
          }
        };

        stopBtn.onclick = () => {
          if (websocket) {
            websocket.close();
          }
          if (workletNode) {
            workletNode.disconnect();
            workletNode = null;
          }
          if (audioContext) {
            audioContext.close();
            audioContext = null;
          }
          startBtn.disabled = false;
          stopBtn.disabled = true;
        };
      </script>
    </footer>
  </body>
</html>
